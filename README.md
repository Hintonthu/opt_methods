# Optimization methods
### Benchmarking optimization methods on convex problems.
## Structure
### First order
Standard methods: Gradient Descent (GD), Polyak's Heavy-ball, Incremental Gradient (IG), Mirror Descent (MD), Nesterov's acceleration (Nesterov).
Adaptive methods: Adagrad, AdGD, Accelerated AdGD (AdgdAccel), Polyak.
### Second order
Standard methods: Newton.
Stochastic methods: Stochastic Newton, Stochastic Cubic Regularization.
### Stochastic first order
Methods: SGD, SVRG, RR.
### Notebooks
Examples of running the methods on convex problems: linear regression, logistic regression, entropy minimization.